{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM5etKIwqXRTX+6whbZL2sd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwnstantinosRoumeliwtis/ML_course/blob/main/ML_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Άσκηση 8**"
      ],
      "metadata": {
        "id": "r2Y0Ep3cqmvl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Επειδή είχα θέμα με το word αρχείο στο preview, που δεν με άφηνε να ανοίξω τα links για το βοηθητικό jupyter και μπόρεσα και άνοιξα μόνο από τον φάκελο old το αρχείο με το mnist dataset. Θα κανω την εργασία με tensorflow που έχω δουλέψει στο προπτυχιακό σαν φοιτητής."
      ],
      "metadata": {
        "id": "ox8QxK72qwcj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1-2\n",
        "Εδώ κατεβάζω το dataset μέσω της kagglehub. Επειδή έπαιξα με τα paths είδα ότι το dataset με τους φακέλους ανα κατηγορία είναι εμφολευμένο σε έναν φάκελο dataset οπότε με την βιβλιοθήκη os ενώνω το path."
      ],
      "metadata": {
        "id": "PaVA5VjKrzhl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "65UCnIGPGDNE",
        "outputId": "223afa93-90da-4a49-9037-7659a9732b17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'dog-breed-image-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/dog-breed-image-dataset\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import kagglehub\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "path = kagglehub.dataset_download(\"khushikhushikhushi/dog-breed-image-dataset\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "dataset_path = os.path.join(path, \"dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3\n",
        "Σε αυτό το σημείο με τη βοήθεια της βιβλιοθήκης tensorflow φορτώνω το dataset και κάθε εικόνα φορτώνει σε μέγεθος 64 * 64 * 3, ζητάω από τη βιβλιοθήκη να ανακατέψει τις εικόνες και αρχικά δίνω batch size = 1 για να μπορέσω να διαχωρίσω train-test set. Αμέσως μετά κάνω unbatch και προσθέτω το dataset στην λίστα all_data. Κρατάω το 80% των δεδομενων για training και το υπόλοιπο για test(Αν δεν έκανα shuffle τότε το test θα γινόταν στις 2 τελευταίες κατηγορίες μόνο που δεν θα είχε εκπαιδευτεί το νευρωνικό δίκτυο). Ύστερα και για το train και για το test κάνω τα tensors batches με size 32. Τέλος με το rescaling πολλαπλασιάζω όλα τα pixels κάθε εικόνας με 1/255 και την κανονικοποιώ φέρνω τις εντάσεις στο εύρος 0-1. Οι επόμενες εντολές είναι καθαρά για την καλύτερη διαχείρηση της gpu και της μνήμης. * * AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds  = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "s6aRSyD8s2gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "full_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    image_size=(64, 64),\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "all_data = list(full_ds.unbatch())\n",
        "total = len(all_data)\n",
        "\n",
        "train_size = int(0.8 * total)\n",
        "\n",
        "train_data = all_data[:train_size]\n",
        "test_data  = all_data[train_size:]\n",
        "\n",
        "train_images = [x for x, y in train_data]\n",
        "train_labels = [y for x, y in train_data]\n",
        "\n",
        "test_images = [x for x, y in test_data]\n",
        "test_labels = [y for x, y in test_data]\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(32)\n",
        "test_ds  = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(32)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds  = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "test_ds  = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "print(\"Train batches:\", train_ds.cardinality().numpy())\n",
        "print(\"Test batches:\", test_ds.cardinality().numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMRfZjXG7oK5",
        "outputId": "57edcc4c-8bec-42d3-bb58-0b1638662586"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 967 files belonging to 10 classes.\n",
            "Train batches: 25\n",
            "Test batches: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Εδώ δημιουργούμε το one hot vectors για κάθε κλάση. Έχουμε 10 κλάσεις οπότε έχουμε labels πχ [0,0,0,0,0,0,0,0,0,1] αν η εικόνα μας ανήκει στην 10η κατηγορία, επειδή έχουμε πολλές κλάσεις, όχι μόνο 2."
      ],
      "metadata": {
        "id": "wqLmNJsRwbgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "\n",
        "def one_hot(images, labels):\n",
        "    labels = tf.one_hot(labels, depth=num_classes)\n",
        "    return images, labels\n",
        "\n",
        "train_ds = train_ds.map(one_hot)\n",
        "test_ds  = test_ds.map(one_hot)"
      ],
      "metadata": {
        "id": "dCcCWkviFn3b"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4-5 . Εδώ δημιουργούμε ένα MLP και του λέμε όλα sequential άρα κάθε νευρώνας ενός layer προωθεί το σήμα σε όλους του επόμενου layer. Λέμε ότι σαν είσοδο θα πάρει τις εικόνες μας σε tensor μεγέθους 64 * 64 * 3 (RGB). Το πρώτο layer έχει 512 νευρώνες, το δεύτερο 256 και το τρίτο 128. Κάθε νευρώνας χρησιμοποιεί συνάρτηση Relu για να ενεργοποιήσει ή όχι το σήμα του. Το τελευταίο layer εξόδου αποτελείται από 10 νευρώνες που έχουν συνάρτηση ενεργοποίησης softmax, δηλαδή στο one hot vector προβλέπεται ένα ποσοστό (πιθανότητα) για κάθε μία από τις 10 κλάσεις."
      ],
      "metadata": {
        "id": "xDcpXp4UxzbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(64, 64, 3)),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkPZ9hlgHxLc",
        "outputId": "e715ece6-e875-40c7-914f-2c0f20cb8e3a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Εδώ θέτουμε τις παραμέτρους για την εκπαίδευση"
      ],
      "metadata": {
        "id": "1t16lOA5zZIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "PJFQPrQSIojg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Εδώ εκπαιδεύουμε για 30 εποχές και εμφανίζουμε το accuracy και το loss ανά εποχή για τα training data."
      ],
      "metadata": {
        "id": "U0mNKfk-zj_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=30\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUUjG8jqIuPE",
        "outputId": "1416d204-b46f-48cb-9129-1cab328118eb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.1186 - loss: 5.9300\n",
            "Epoch 2/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2319 - loss: 2.1456\n",
            "Epoch 3/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3078 - loss: 2.1443\n",
            "Epoch 4/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4161 - loss: 1.7635\n",
            "Epoch 5/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4996 - loss: 1.4991\n",
            "Epoch 6/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5877 - loss: 1.2978\n",
            "Epoch 7/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6451 - loss: 1.0695\n",
            "Epoch 8/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7658 - loss: 0.7518\n",
            "Epoch 9/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8301 - loss: 0.6117\n",
            "Epoch 10/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8736 - loss: 0.5011\n",
            "Epoch 11/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8873 - loss: 0.4297\n",
            "Epoch 12/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8939 - loss: 0.3929\n",
            "Epoch 13/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9180 - loss: 0.3689\n",
            "Epoch 14/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8886 - loss: 0.3875\n",
            "Epoch 15/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9582 - loss: 0.1733\n",
            "Epoch 16/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9755 - loss: 0.1205\n",
            "Epoch 17/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.0769\n",
            "Epoch 18/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.1020\n",
            "Epoch 19/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 0.0750\n",
            "Epoch 20/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9383 - loss: 0.1753\n",
            "Epoch 21/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9736 - loss: 0.1273\n",
            "Epoch 22/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9496 - loss: 0.1559\n",
            "Epoch 23/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9756 - loss: 0.1019\n",
            "Epoch 24/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9662 - loss: 0.1237\n",
            "Epoch 25/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9936 - loss: 0.0403\n",
            "Epoch 26/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0249\n",
            "Epoch 27/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9910 - loss: 0.0419\n",
            "Epoch 28/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0700\n",
            "Epoch 29/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9945 - loss: 0.0268\n",
            "Epoch 30/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Εδώ κάνουμε predict στα test δεδομένα και εμφανίζουμε accuracy και loss."
      ],
      "metadata": {
        "id": "mACATqf7zyOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(\"Test accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2zzYq28djuN",
        "outputId": "b6bc2b9e-b108-4272-dfcf-23e0c953b5e3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0209\n",
            "Test accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7\n",
        " Εδώ δημιουργούμε ένα cnn στην είσοδο έχουμε 32 filters μεγέθους 3*3, στο επόμενο layer 64 kernels, στο επόμενο 128 και στο τέλος προσθέτουμε ένα μη cnn layer το οποίο κάνει την δουλειά της ταξινόμησης αφού εξάγαμε τα τοπικά χαρακτηριστικά από τα cnn layers. Ύστερα η προώθηση γίνεται στο layer εξόδου το οποίο αποτελείται από 10 νευρώνες και χρησιμοποιεί softmax σε αντίθεση με όλους τους νευρώνες των προηγούμενων layers πoυ χρησιμοποιούσαν ReLU. Εδώ να σημειώσουμε ότι μετά από κάθε cnn layer κάναμε max pooling. Το καλύτερο μοντέλο είναι το CNN διότι έχει μεγαλύτερη ακρίβεια και πιο γρήγορη σύγκλιση. Αυτό γίνεται γιατί το CNN με τα kernels εξάγει τα τοπικά χαρακτηριστικά των εικόνων και δίνει για ταξινόμηση καλύτερα features στο dense layer. Ανιχνεύει κρυφά χαρακτηριστικά, ακμές γεγονός που βοηθάει στην ταξινόμηση των κατηγοριών."
      ],
      "metadata": {
        "id": "xtoFd8If0LLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "modelcnn = models.Sequential([\n",
        "    layers.Input(shape=(64, 64, 3)),\n",
        "\n",
        "    layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "-pdGECN6b3A8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelcnn.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "ezUOIavKcJ7Q"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = modelcnn.fit(\n",
        "    train_ds,\n",
        "    epochs=30\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pwbwAkecRYY",
        "outputId": "9972cb24-8cff-401d-ecf0-15de93bb5c3a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.1251 - loss: 2.3141\n",
            "Epoch 2/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1697 - loss: 2.2304\n",
            "Epoch 3/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3701 - loss: 1.7864\n",
            "Epoch 4/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6137 - loss: 1.1377\n",
            "Epoch 5/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8310 - loss: 0.5788\n",
            "Epoch 6/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9360 - loss: 0.2388\n",
            "Epoch 7/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9838 - loss: 0.0887\n",
            "Epoch 8/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9762 - loss: 0.0762\n",
            "Epoch 9/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9944 - loss: 0.0283\n",
            "Epoch 10/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0098\n",
            "Epoch 11/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0047\n",
            "Epoch 12/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0018\n",
            "Epoch 13/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.8560e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 7.4137e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.1411e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.2475e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.8486e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.4980e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.5979e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.1406e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.9537e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.6290e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.7821e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.4562e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.2885e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.0495e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.7101e-05\n",
            "Epoch 28/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.4053e-05\n",
            "Epoch 29/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.9951e-05\n",
            "Epoch 30/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.1737e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = modelcnn.evaluate(test_ds)\n",
        "print(\"Test accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_935-_idyPn",
        "outputId": "d2ca8c54-5f4c-4b8b-e21c-49103528a5af"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 7.0340e-05\n",
            "Test accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8)\n",
        "Εδώ παρ'ότι η ακρίβεια είναι 100% θα εφαρμόσω batch normalization."
      ],
      "metadata": {
        "id": "mT9omMLGCqTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn_batch_normalization = models.Sequential([\n",
        "    layers.Input(shape=(64, 64, 3)),\n",
        "\n",
        "    layers.Conv2D(32, (3,3), padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Conv2D(64, (3,3), padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Conv2D(128, (3,3), padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_cnn_batch_normalization.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model_cnn_batch_normalization.fit(\n",
        "    train_ds,\n",
        "    epochs=30\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model_cnn_batch_normalization.evaluate(test_ds)\n",
        "print(\"Test accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmoTcn8nD4xq",
        "outputId": "3ff0a555-1124-4a23-8987-c9ba08dc7157"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 101ms/step - accuracy: 0.4554 - loss: 1.8622\n",
            "Epoch 2/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9947 - loss: 0.2040\n",
            "Epoch 3/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9981 - loss: 0.0543\n",
            "Epoch 4/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0230\n",
            "Epoch 5/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0151\n",
            "Epoch 6/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0113\n",
            "Epoch 7/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0087\n",
            "Epoch 8/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0068\n",
            "Epoch 9/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0060\n",
            "Epoch 10/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0053\n",
            "Epoch 11/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0048\n",
            "Epoch 12/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0040\n",
            "Epoch 13/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0035\n",
            "Epoch 14/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0033\n",
            "Epoch 15/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0028\n",
            "Epoch 16/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0027\n",
            "Epoch 17/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0025\n",
            "Epoch 18/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0023\n",
            "Epoch 19/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0024\n",
            "Epoch 20/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0021\n",
            "Epoch 21/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 22/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0016\n",
            "Epoch 23/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 24/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0014\n",
            "Epoch 25/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 26/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0014\n",
            "Epoch 27/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0012\n",
            "Epoch 28/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 29/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 30/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Test accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}